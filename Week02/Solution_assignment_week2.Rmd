---
title: "Solution and notes for the assignment Week 2 - Demonstration of the central limit theorem"
author: "Torbj√∏rn Ergon"
date: '`r Sys.Date()`'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The central limit theorem

The central limit theorem states that the sampling distribution of the *mean* of several independent stochastic variables approaches a normal distribution as sample size increases, regardless of the distribution of the variables.

I will here demonstrate that this applies to the mean of values drawn from an exponential distribution, but you can pick any distribution in your own example. I will answer point 1 and the optional point 2 in the assignment in parallel.  

## Example - lifetimes of juvenile fish

In my example, I will look at the sampling distribution of mean lifetime (i.e., age at death) in a sample of juvenile fish (fry). If the mortality rate $m$ is constant over time, then lifetime will be exponentially distributed with mean $1/m$ ($m$ is more generally called a hazard rate). I will for simplicity assume that all individuals in the population are equal with $m = 0.01$ days$^{-1}$ such that mean life-time in the population is $1/m = 100$ days.

In a natural population, it may be impossible to observe the exact time of death of individuals, but let's here pretend that we can. Let's start by looking at the distribution of individual lifetimes in the population by making a simple simulation.

```{r}
lifetimes = rexp(100000, 0.01)
hist(lifetimes, freq = FALSE)
```

Here I have drawn 100 000 individual lifetimes and plotted a histogram of the values. The argument `freq = FALSE` in the `hist` function specify that the y-axis should be scaled such that the area of the histogram equals one, and thus the result resembles a probability distribution. I could have plotted the theoretical probability distribution directly using the `dexp` function, but with a sample size of 100 000, the histogram will be very close to the theoretical distribution thanks to the law of large numbers.

We see from the histogram that most individuals live less than 200 days but a few live for more than a thousand days. Let's check that the mean lifetime is indeed close to the theoretical value of $1/m = 100$ days:

```{r}
mean(lifetimes)
```

## Simulating the sampling distribution of mean lifetimes in a sample of two individuals

If we pick two random individuals from the population and follow them until they die, we can compute their mean lifetime. If we pick two other individuals at random we will get a different value for mean lifetime. Every time we pick two individuals and compute their mean lifetime, we would get a different value. In other words, the mean of two random lifetimes is a random (= 'stochastic') variable. It is not easy to find a mathematical expression for the distribution of the mean of random variables (sometimes it is impossible), but we can easily simulate the distribution. Let us do that for our case in the same way we did in the tutorial:

```{r}
n = 2    # sample size
m = 0.01 # mortality rate in the population
n_iter = 100000
mean_lifetime = rep(NA, n_iter)
for(i in 1:n_iter){
    lifetime = rexp(n, m) # Random lifetimes when mortality rate is constant over time
    mean_lifetime[i] = mean(lifetime)
}
hist(mean_lifetime, freq = FALSE, main = paste("Sample size =", n))
```

We here see that the sampling distribution of mean lifetime of only two individuals is highly skewed towards high values. The mode (i.e., the location of the highest point of the distribution) is not at the very lowest values (as it is for the exponential distribution), but the distribution looks far from a bell shaped normal distribution. A qq-plot confirms this:

```{r}
qqnorm(mean_lifetime)
qqline(mean_lifetime)
```


Before we move on, we can stop to check if the standard deviation of mean lifetime of two individuals is close to the expected value. In the tutorial (and in STK1000) you learned that the the standard deviation of the mean of $n$ independent draws from a population with standard deviation $\sigma$ is $\sigma/\sqrt{n}$. Wikipedia says that the variance of an exponentially distributed variable is $1/m^2$ which means that the standard deviation is $1/m$. With a sample size of $n=2$ we then get that the standard deviation of mean lifetime of two individuals should be $1/(m\sqrt{2})$. Let's check that the standard deviation of our simulated mean values is close to this:

```{r}
(theoretical_SEM = (1/m)/sqrt(2))
(empirical_SEM = sd(mean_lifetime))
```

We can also superimpose a normal distribution with the above standard deviation on the histogram for the simulated mean lifetimes (since the theoretical and empirical standard deviation is so close, it doesn't really matter which one we use):

```{r}
hist(mean_lifetime, freq = FALSE, main = paste("Sample size =", n))
xx = seq(min(mean_lifetime), max(mean_lifetime), length.out=100)
lines(xx, dnorm(xx, mean(mean_lifetime), sd(mean_lifetime)), col="red")
```


## Simulating the sampling distribution of mean lifetimes in a sample of $n$ individuals

The central limit theorem states that the distribution of the mean will approach a normal distribution when we increase sample size. We can test this by increasing the sample size in the simulation above. To avoid having to copy and paste the code several times, I instead put the code in a function that we can call several times with different sample sizes.

```{r}
SimMeanLifetimes = function(n, m = 0.01, n_iter = 100000){
    mean_lifetime = rep(NA, n_iter)
    for(i in 1:n_iter){
        lifetime = rexp(n, m) # Random lifetimes when mortality rate is constant over time
        mean_lifetime[i] = mean(lifetime)
    }
    par(mfrow=c(1,2))
    hist(mean_lifetime, freq = FALSE, main = paste("Sample size =", n))
    xx = seq(min(mean_lifetime), max(mean_lifetime), length.out=100)
    lines(xx, dnorm(xx, mean(mean_lifetime), sd(mean_lifetime)), col="red")
    qqnorm(mean_lifetime)
    qqline(mean_lifetime)
}
```

We can now run the simulations and produce the plots with several sample sizes.

```{r}
SimMeanLifetimes(n = 2)
SimMeanLifetimes(n = 5)
SimMeanLifetimes(n = 10)
SimMeanLifetimes(n = 20)
SimMeanLifetimes(n = 50)
SimMeanLifetimes(n = 100)
SimMeanLifetimes(n = 200)
SimMeanLifetimes(n = 1000)
```

Here we see that the mean is very close to having a normal distribution when sample size is 1000, but the normal approximation is already quite good with a sample size of 100. How many samples you need before the normal approximation is good depends on how skewed the distribution draw from is. With other distributions, the normal approximation may be a lot better for smaller sample sizes.

## Number of iterations and convergence (not part of the assignment)

Repeating a simulation in a loop many times to investigate the distribution of some statistic (see the [Glossary](https://uio.instructure.com/courses/37153/pages/glossary)), like we have done here, is a type of simulations called Monte Carlo simulations.

We experience that students sometimes confuse number of iterations of the Monte Carlo simulations with sample size. Number of iterations is *not* a property of the *nature* you are simulating, it is just the number of times you choose to repeat the simulations in order to generate the distribution you are interested in. Number of iterations just needs to be high enough for us to trust the results (the 'Law of large numbers' comes in here). If adding even more iterations changes the result by very little (we can decide this "tolerance"), we say that the Monte Carlo simulations have *converged*.

We can look at the convergence of the Monte Carlo simulations by computing e.g., the standard deviation of the statistic we are simulating (mean life time in this case) for the simulated values so far in the Monte Carlo simulations at every iteration (i.e., first the standard deviation of the first two values, then the first three, four, and so on). Below, we do just this when we have a sample size of 5 and then plot the result.

```{r}
n = 5
m = 0.01
n_iter = 20000
mean_lifetime = sd_mean_lifetime = rep(NA, n_iter)
for(i in 1:n_iter){
    lifetime = rexp(n, m) # Random lifetimes when mortality rate is constant over time
    mean_lifetime[i] = mean(lifetime)
    sd_mean_lifetime[i] = sd(mean_lifetime, na.rm=TRUE)
}
plot(1:n_iter, sd_mean_lifetime, type="l", xlab="Iteration", ylab="SD of the mean")
(theoretical_SEM = (1/m)/sqrt(n))
abline(h = theoretical_SEM, col="red")
```

The red line here is the theoretical standard deviation of the mean that we computed earlier. We see that the Monte Carlo simulations have not yet converged very well at 1000 iterations, but the convergence is pretty good at 20 000 iterations. In the Monte Carlo simulations we did earlier, we used 100 000 iterations, so this should be plenty.
